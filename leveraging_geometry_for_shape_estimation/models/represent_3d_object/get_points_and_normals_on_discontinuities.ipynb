{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import sys\n",
    "import socket\n",
    "import pickle\n",
    "import math\n",
    "import os\n",
    "import json\n",
    "from tqdm import tqdm\n",
    "import torch\n",
    "import k3d\n",
    "from shutil import copytree\n",
    "\n",
    "from pytorch3d.io import load_obj,save_ply\n",
    "from pytorch3d.ops import sample_points_from_meshes,knn_points,sample_farthest_points\n",
    "from pytorch3d.structures import Pointclouds,Meshes\n",
    "import trimesh\n",
    "\n",
    "from leveraging_geometry_for_shape_estimation.models.represent_3d_object.extract_points_from_models import find_edge_points,load_points_normals,sample_points_from_lines,repair_mesh,plot_points,different_normals_around_points,vis_representative_normals\n",
    "from leveraging_geometry_for_shape_estimation.models.represent_3d_object.moller_trumbore import inside_mesh\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"/scratch2/fml35/experiments/leveraging_geometry_for_shape/exp_117_scannet_models/models/model_list.json\",'r') as f:\n",
    "    model_list = json.load(f)[\"models\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model/bathtub/38773e1ff9871cb33321831d2245cf06/model_normalized.obj\n"
     ]
    }
   ],
   "source": [
    "n_points = 50000\n",
    "n_points_ref = 50000\n",
    "n_nn = 5\n",
    "angle_threshold_degree = 20\n",
    "scannet_path = '/scratch2/fml35/datasets/shapenet_v2/ShapeNetRenamed/'\n",
    "j = 0\n",
    "device = torch.device(\"cpu\")\n",
    "print(model_list[j][\"model\"])\n",
    "\n",
    "model_list[j][\"model\"] = \"model_fixed/cabinet/4ec97e83a1e9725c77a332e31ab74b68/model_normalized.obj\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([89906, 3])\n",
      "faces torch.Size([179808, 3])\n",
      "vertices (88982, 3)\n",
      "faces (177960, 3)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "sample_points,sample_normals = load_points_normals(scannet_path + model_list[j][\"model\"],n_points)\n",
    "edge_points = find_edge_points(sample_points,sample_normals,n_nn,angle_threshold_degree,device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([50000, 3])\n",
      "torch.Size([50000, 3])\n",
      "torch.Size([6439, 3])\n"
     ]
    }
   ],
   "source": [
    "print(sample_points.shape)\n",
    "print(sample_normals.shape)\n",
    "print(edge_points.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "verts_torch,faces_torch,_ = load_obj(scannet_path + model_list[j][\"model\"],load_textures=False)\n",
    "# faces_fixed = repair_mesh(verts_torch,faces_torch[0])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2aeb65c62d7247d5b7891e6ca0390c51",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 300, 3])\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9323e3eea2624b7fbee0324cce8a4b83",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plot_points(edge_points)\n",
    "furthest_points,indices = sample_farthest_points(edge_points.unsqueeze(0),K=torch.Tensor([300]))\n",
    "print(furthest_points.shape)\n",
    "plot_points(furthest_points.squeeze(0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "ref_points,ref_normals = load_points_normals(scannet_path + model_list[j][\"model\"],n_points_ref)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([300, 3, 3])\n"
     ]
    }
   ],
   "source": [
    "\n",
    "representative_normals = different_normals_around_points(furthest_points.squeeze(0),ref_points,ref_normals,n_nn=20,n_normals_per_point=3)\n",
    "\n",
    "print(representative_normals.shape)\n",
    "# print(representative_normals)[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/scratch/fml35/environments/shape_env_octo/lib/python3.6/site-packages/traittypes/traittypes.py:101: UserWarning: Given trait value dtype \"int64\" does not match required type \"uint32\". A coerced copy has been created.\n",
      "  np.dtype(self.dtype).name))\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "873e98de00284bad8a59783d865c0dd1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "\n",
    "verts_torch,faces_torch,_ = load_obj(scannet_path + model_list[j][\"model\"],load_textures=False)\n",
    "# faces = faces_torch[0]\n",
    "# vertices,faces = repair_mesh(verts_torch,faces_torch[0])\n",
    "# plt_mesh = k3d.mesh(vertices.numpy(),faces.numpy())\n",
    "plt_mesh = k3d.mesh(verts_torch.numpy(),faces_torch[0].numpy())\n",
    "vis_representative_normals(furthest_points.squeeze(0),representative_normals,plt_mesh)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def ensure_normals_facing_out(points,normals,vertices,faces,mesh=None):\n",
    "\n",
    "#     plot = k3d.plot()\n",
    "\n",
    "#     for i in range(1):\n",
    "#         # print(points.shape)\n",
    "#         # print(normals.shape)\n",
    "#         lines = torch.cat([points,points+normals[:,i]*0.05],dim=1)\n",
    "#         # print(lines.shape)\n",
    "#         check_points = sample_points_from_lines(lines,points_per_line=30)\n",
    "#         check_points = check_points.view(-1,3)\n",
    "#         check_points = check_points[10:11]\n",
    "#         # print('checl points',check_points.shape)\n",
    "#         inside,intersection = inside_mesh(check_points,vertices,faces)\n",
    "#         print(inside.shape)\n",
    "#         # print('inside',inside[:100])\n",
    "#         colors = inside * 255\n",
    "\n",
    "#         indices = torch.nonzero(intersection.squeeze())\n",
    "#         indices = indices.squeeze()\n",
    "#         # print('indices',indices)\n",
    "#         # print('faces',faces.shape)\n",
    "#         # print('faces[indices]',faces[indices])\n",
    "#         # print(faces[indices])\n",
    "#         points_faces_hit = vertices[faces[indices].view(-1)]\n",
    "#         # colors = get_colors(values,default_range=default_range)\n",
    "#         print('faces[indices]',faces[indices])\n",
    "#         print('points_faces_hit.shape',points_faces_hit.shape)\n",
    "#         print('points_faces_hit',points_faces_hit)\n",
    "#         # colors = np.round(np.array(colors)*255).astype(int)[:,:3]\n",
    "#         # multi = np.array([1,256,256*256])\n",
    "#         # colors = np.dot(colors,multi)\n",
    "#         plot += k3d.points(points_faces_hit, point_size=0.03,color=0xff0000, shader=\"flat\")\n",
    "\n",
    "#         plot += k3d.points(check_points, point_size=0.003,colors=colors, shader=\"flat\")\n",
    "#         if mesh is not None:\n",
    "#             plot += mesh\n",
    "\n",
    "#     plot.display()\n",
    "\n",
    "# # print(faces_torch[0])\n",
    "# ensure_normals_facing_out(furthest_points.squeeze(0)[3:4],representative_normals[3:4],verts_torch,faces_torch[0],plt_mesh) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "points_normals = np.load('/scratch2/fml35/experiments/leveraging_geometry_for_shape/exp_117_scannet_models/models/representation_points_and_normals/exp_01/points_and_normals/{}.npz'.format(model_list[j][\"name\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model/cabinet/4ec97e83a1e9725c77a332e31ab74b68/model_normalized.obj\n",
      "(300, 3)\n",
      "(300, 3, 3)\n",
      "[[[ 4.6247542e-03 -9.7900903e-01 -2.0376441e-01]\n",
      "  [-4.0971637e-03  9.6985346e-01  2.4365473e-01]\n",
      "  [-7.9515949e-03  1.7119370e-01  9.8520529e-01]]\n",
      "\n",
      " [[-5.7094508e-01  4.3822411e-01  6.9424874e-01]\n",
      "  [-1.2260204e-03 -9.9977660e-01  2.1101112e-02]\n",
      "  [ 0.0000000e+00 -1.5198085e-01  9.8838341e-01]]\n",
      "\n",
      " [[ 5.5322784e-01  4.5818186e-01  6.9570702e-01]\n",
      "  [ 3.6097512e-02 -9.9842054e-01  4.3049473e-02]\n",
      "  [ 6.0144728e-01 -6.4008790e-01  4.7806776e-01]]\n",
      "\n",
      " [[-7.0243472e-01  7.1174824e-01  0.0000000e+00]\n",
      "  [-3.0554088e-02 -9.9953312e-01  8.3858453e-05]\n",
      "  [-9.9070174e-01 -1.3605183e-01 -1.2557355e-10]]\n",
      "\n",
      " [[ 7.0227164e-01  7.1190906e-01  0.0000000e+00]\n",
      "  [ 2.5627907e-02 -9.9967158e-01 -3.1588966e-06]\n",
      "  [ 7.6705152e-01 -6.4158541e-01  0.0000000e+00]]\n",
      "\n",
      " [[-6.3602300e-03 -8.6518967e-01  5.0140446e-01]\n",
      "  [-2.3793674e-03  9.6195030e-01 -2.7321407e-01]\n",
      "  [ 9.5944321e-03  4.5346594e-01 -8.9122188e-01]]\n",
      "\n",
      " [[ 3.0866206e-01  9.5117176e-01  1.2316369e-04]\n",
      "  [-1.0286608e-01 -9.9469519e-01 -3.2466452e-04]\n",
      "  [ 9.6246171e-01  2.7141762e-01  1.2460077e-04]]\n",
      "\n",
      " [[ 4.3841159e-01 -8.9877409e-01 -6.7873235e-04]\n",
      "  [-3.1154597e-01  9.5023096e-01  5.8813882e-04]\n",
      "  [-9.6292394e-01  2.6977286e-01  9.5331343e-05]]\n",
      "\n",
      " [[ 0.0000000e+00  7.0644808e-01 -7.0776486e-01]\n",
      "  [ 2.2753816e-06 -9.9958384e-01 -2.8847247e-02]\n",
      "  [-0.0000000e+00 -1.5229622e-01 -9.8833489e-01]]\n",
      "\n",
      " [[ 0.0000000e+00 -1.0000000e+00  0.0000000e+00]\n",
      "  [ 9.8480242e-01 -0.0000000e+00  1.7367856e-01]\n",
      "  [-9.7814834e-01 -1.4325975e-02 -2.0741434e-01]]]\n"
     ]
    }
   ],
   "source": [
    "print(model_list[j][\"model\"])\n",
    "print(points_normals[\"points\"].shape)\n",
    "print(points_normals[\"normals\"].shape)\n",
    "print(points_normals[\"normals\"][:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "broken [5651 5652 5469 5470 5649 5650 5512 5513]\n",
      "broken [5651 5652 5469 5470 5649 5650 5512 5513]\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d477aa4ad8904184ac9069715bf753f6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "verts_torch,faces_torch,_ = load_obj(scannet_path + model_list[j][\"model\"],load_textures=False)\n",
    "# faces = faces_torch[0]\n",
    "vertices,faces = repair_mesh(verts_torch,faces_torch[0])\n",
    "plt_mesh = k3d.mesh(vertices.numpy(),faces.numpy())\n",
    "vis_representative_normals(torch.from_numpy(points_normals['points']),torch.from_numpy(points_normals['normals']),plt_mesh)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (shape_env_octo)",
   "language": "python",
   "name": "shape_env_octo"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
