{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from tqdm import tqdm\n",
    "import os\n",
    "import numpy as np\n",
    "import k3d\n",
    "from pytorch3d.io import load_objs_as_meshes, save_obj, load_obj,save_ply\n",
    "\n",
    "from leveraging_geometry_for_shape_estimation.models.represent_3d_object.get_mask_for_points import get_rotations,get_masks_all_orientations\n",
    "from leveraging_geometry_for_shape_estimation.models.represent_3d_object.extract_points_from_models import vis_representative_normals\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "def vis_masks(mask_dict,point_norm,vis_dir,model,vertices,faces):\n",
    "    \n",
    "    furthest_points = point_norm['points']\n",
    "    representative_normals = point_norm['normals']\n",
    "\n",
    "    counter = 0\n",
    "    for key in mask_dict:\n",
    "        mask = mask_dict[key]\n",
    "        vis_points = vis_representative_normals(torch.from_numpy(furthest_points[mask,:]),torch.from_numpy(representative_normals[mask,:,:]),in_notebook=False)\n",
    "\n",
    "        vis_points_all = vis_representative_normals(torch.from_numpy(furthest_points),torch.from_numpy(representative_normals),in_notebook=False)\n",
    "        \n",
    "        plot = k3d.plot()\n",
    "        plot += k3d.points(vis_points.cpu().numpy(), point_size=0.01,color=0xff ,shader=\"flat\")\n",
    "        plot += k3d.points(vis_points_all.cpu().numpy(), point_size=0.01,color=0xffff ,shader=\"flat\")\n",
    "        plot += k3d.points(vis_points.cpu().numpy(), point_size=0.01,color=0xff ,shader=\"flat\")\n",
    "        plot += k3d.mesh(vertices.cpu().numpy(), faces[0].cpu().numpy(), textures=None, shader=\"flat\")\n",
    "        plot.display()\n",
    "\n",
    "        counter += 1 \n",
    "        if counter == 1:\n",
    "            break\n",
    "def main():\n",
    "    # model_path = '/scratch2/fml35/datasets/shapenet_v2/ShapeNetRenamed/model/cabinet/23aeb8fdc0d1ed4c4da5feafe6f1c8fc/model_normalized.obj'\n",
    "    input_dir = '/scratch/fml35/datasets/shapenet_v2/ShapeNetRenamed/representation_points_and_normals/exp_02/points_and_normals/'\n",
    "    model_3d_dir = '/scratch/fml35/datasets/shapenet_v2/ShapeNetRenamed/model_fixed/'\n",
    "\n",
    "    model_path = model_3d_dir + 'bathtub/4a6ed9c61b029d15904e03fa15bd73ec/model_normalized.obj'\n",
    "    point_norm_path = input_dir + 'bathtub_4a6ed9c61b029d15904e03fa15bd73ec.npz'\n",
    "\n",
    "    gamma = 0.03\n",
    "\n",
    "    device = torch.device(\"cuda:0\")\n",
    "    R_mesh,T_mesh,elev,azim = get_rotations(device)\n",
    "\n",
    "    for model in sorted(os.listdir(input_dir))[:1]:\n",
    "        # model_path = model_3d_dir + model.split('_')[0] + '/' + model.split('_')[1].split('.')[0] + '/model_normalized.obj'\n",
    "        # point_norm_path = input_dir + model\n",
    "\n",
    "        mask_dict,point_norm = get_masks_all_orientations(R_mesh,T_mesh,elev,azim,model_path,point_norm_path,device,gamma) \n",
    "        # vertices,faces,textures = load_obj(model_path ,load_textures=False,device=device)\n",
    "\n",
    "        # if np.random.rand() > 0.0 and point_norm != None:\n",
    "        #     vis_masks(mask_dict,point_norm,output_dir_vis,model,vertices,faces)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "after smaller than dist\n",
      "intersects torch.Size([810])\n",
      "smaller_than_distance_face torch.Size([810])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 810/810 [00:00<00:00, 25404.44it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "befre mask\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7b390210bc4f4993b1bd9aa98e2ec809",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "elev_015_azim_292.5.npy\n"
     ]
    }
   ],
   "source": [
    "main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "8360add7f74764e675e0d6f8d586f7f3a1b7683cd8721298d637715b6d19511e"
  },
  "kernelspec": {
   "display_name": "Python 3.6.9 ('shape_env_octo')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
