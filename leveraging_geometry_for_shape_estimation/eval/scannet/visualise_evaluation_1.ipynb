{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "** fvcore version of PathManager will be deprecated soon. **\n",
      "** Please migrate to the version in iopath repo. **\n",
      "https://github.com/facebookresearch/iopath \n",
      "\n"
     ]
    }
   ],
   "source": [
    "import imageio\n",
    "import numpy as np\n",
    "import cv2\n",
    "import json\n",
    "import torch\n",
    "from scipy.spatial.transform import Rotation as scipy_rot\n",
    "import sys\n",
    "from torchvision.models import vgg16\n",
    "from PIL import Image\n",
    "from matplotlib import pyplot as plt\n",
    "import itertools\n",
    "import k3d\n",
    "from pytorch3d.io import load_objs_as_meshes, save_obj, load_obj, save_ply\n",
    "import pandas as pd\n",
    "from leveraging_geometry_for_shape_estimation.eval.scannet.CSVHelper import read as read_csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_mesh(shapenet_path,category,model_id,r,t,s):\n",
    "\n",
    "    vertices,faces,properties = load_obj('{}/{}/{}/model_normalized.obj'.format(shapenet_path,category.replace('bookcase','bookshelf'),model_id),create_texture_atlas=False, load_textures=False)\n",
    "\n",
    "    vertices = vertices.cpu().numpy()\n",
    "    vertices_scaled = np.array(s) * vertices\n",
    "    vertices =  np.matmul(np.array(r),vertices_scaled.T).T + np.array(t)\n",
    "    return vertices,faces[0].numpy()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def writePlyFile(file_name, vertices, colors):\n",
    "    ply_header = '''ply\n",
    "                format ascii 1.0\n",
    "                element vertex %(vert_num)d\n",
    "                property float x\n",
    "                property float y\n",
    "                property float z\n",
    "                property uchar red\n",
    "                property uchar green\n",
    "                property uchar blue\n",
    "                end_header\n",
    "               '''\n",
    "    print(vertices.shape)\n",
    "    print(colors.shape)\n",
    "    vertices = vertices.reshape(-1, 3)\n",
    "    colors = colors.reshape(-1, 3)\n",
    "    vertices = np.hstack([vertices, colors])\n",
    "    with open(file_name, 'w') as f:\n",
    "      f.write(ply_header % dict(vert_num=len(vertices)))\n",
    "      np.savetxt(f, vertices, '%f %f %f %d %d %d')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('/scratch2/fml35/results/ROCA/debug_evaluation/gt_scene0011_00_bin.json','r') as f:\n",
    "    gt = json.load(f)\n",
    "\n",
    "with open('/scratch2/fml35/results/ROCA/debug_evaluation/single_pred_scene0011_00_bin.json','r') as f:\n",
    "    pred = json.load(f)\n",
    "shapenet_path = '/scratch2/fml35/datasets/shapenet_v2/ShapeNetRenamed/model'\n",
    "# plot = k3d.plot()\n",
    "\n",
    "# vert_pred,face_pred = load_mesh(shapenet_path,pred[\"category\"],pred[\"id_cad\"],pred[\"r\"],pred[\"t\"],pred[\"s\"])\n",
    "# plot += k3d.mesh(vert_pred,face_pred,color=(255 + 128 * 256))\n",
    "\n",
    "# all_verts = [vert_pred]\n",
    "\n",
    "# for i in range(len(gt[\"category\"])):\n",
    "#     vert_gt,face_gt = load_mesh(shapenet_path,gt[\"category\"][i],gt[\"id_cad\"][i],gt[\"r\"][i],gt[\"t\"][i],gt[\"s\"][i])\n",
    "#     plot += k3d.mesh(vert_gt,face_gt,color=(64 + 128 * 256))\n",
    "#     all_verts.append(vert_gt)\n",
    "\n",
    "# stacked = np.concatenate(all_verts)\n",
    "# stacked = torch.Tensor(stacked)\n",
    "\n",
    "# save_ply('/scratch2/fml35/results/ROCA/debug_evaluation/test_vis.ply',stacked)\n",
    "\n",
    "# plot.display()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_scene(scene,plot_scene=False):\n",
    "    with open('/scratch2/fml35/results/ROCA/results_per_scene/{}.json'.format(scene),'r') as f:\n",
    "        annotations = json.load(f)\n",
    "\n",
    "    with open('/scratch2/fml35/results/ROCA/results_per_scene_reformated/{}.json'.format(scene),'r') as f:\n",
    "        annotations_filtered = json.load(f)\n",
    "\n",
    "    with open('/scratch2/fml35/results/ROCA/gt_per_scene/{}.json'.format(scene),'r') as f:\n",
    "        annotations_gt = json.load(f)\n",
    "    print('N',len(annotations),\"N filtered \",len(annotations_filtered))\n",
    "    plot = k3d.plot()\n",
    "    distances = []\n",
    "\n",
    "    all_verts_colors = {'verts':[],'colors':[]}\n",
    "\n",
    "\n",
    "    for i in range(len(annotations)):\n",
    "        print(annotations[i])\n",
    "        if not annotations[i][\"id_cad\"] == 'b1da0d9aab6d2308608505d960f2a393' or not annotations[i][\"score\"] == 0.9721203446388245:\n",
    "            continue\n",
    "        vert,face = load_mesh(shapenet_path,annotations[i][\"category\"],annotations[i][\"id_cad\"],annotations[i][\"r\"],annotations[i][\"t\"],annotations[i][\"s\"])\n",
    "\n",
    "        plot += k3d.mesh(vert,face,color=(128 * 256*256))\n",
    "        all_verts_colors[\"verts\"] = all_verts_colors[\"verts\"] + list(vert)\n",
    "        all_verts_colors[\"colors\"] = all_verts_colors[\"colors\"] + [[0,255,0] for v in list(vert)]\n",
    "    \n",
    "    for i in range(len(annotations_filtered)):\n",
    "        if not annotations[i][\"id_cad\"] == 'b1da0d9aab6d2308608505d960f2a393' or not annotations[i][\"score\"] == 0.9721203446388245:\n",
    "            continue\n",
    "\n",
    "        vert,face = load_mesh(shapenet_path,annotations_filtered[i][\"category\"],annotations_filtered[i][\"id_cad\"],annotations_filtered[i][\"r\"],annotations_filtered[i][\"t\"],annotations_filtered[i][\"s\"])\n",
    "        plot += k3d.mesh(vert,face,color=(255 + 128 * 256))\n",
    "\n",
    "        dist = np.array(annotations_filtered[i][\"t\"])-np.array(annotations[i][\"t\"])\n",
    "        distances.append(dist)\n",
    "        all_verts_colors[\"verts\"] = all_verts_colors[\"verts\"] + list(vert)\n",
    "        \n",
    "        all_verts_colors[\"colors\"] = all_verts_colors[\"colors\"] + [[255,0,0] for v in list(vert)]\n",
    "        # print('dist',np.array(annotations_filtered[i][\"t\"])-np.array(annotations[i][\"t\"]))\n",
    "    for i in range(len(annotations_gt)):\n",
    "        if not annotations[i][\"id_cad\"] == 'b1da0d9aab6d2308608505d960f2a393':\n",
    "            continue\n",
    "        vert,face = load_mesh(shapenet_path,annotations_gt[i][\"category\"],annotations_gt[i][\"id_cad\"],annotations_gt[i][\"r\"],annotations_gt[i][\"t\"],annotations_gt[i][\"s\"])\n",
    "        plot += k3d.mesh(vert,face,color=(128 * 256))\n",
    "\n",
    "\n",
    "    writePlyFile('/scratch2/fml35/results/ROCA/vis_scenes_1/{}.ply'.format(scene),np.array(all_verts_colors[\"verts\"]),np.array(all_verts_colors[\"colors\"]))\n",
    "    # distances = np.array(distances)\n",
    "    # diff_distances = distances - distances[0,:]\n",
    "    # magnitude = np.linalg.norm(diff_distances,axis=1)\n",
    "    # # assert np.max(magnitude) < 0.00001, (magnitude)\n",
    "    # print('assertion failed')\n",
    "    # if plot_scene:\n",
    "    #     plot.display()\n",
    "\n",
    "    #     plot.fetch_screenshot()\n",
    "    #     with open('/scratch2/fml35/results/ROCA/vis_scenes/{}.html'.format(scene),'w') as fp:\n",
    "    #         fp.write(plot.snapshot)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: '/scratch2/fml35/results/ROCA/results_per_scene/scene0621_00.json'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_32508/1782359860.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mscene\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"scene0621_00\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mplot_scene\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mscene\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mplot_scene\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/tmp/ipykernel_32508/348563031.py\u001b[0m in \u001b[0;36mplot_scene\u001b[0;34m(scene, plot_scene)\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mplot_scene\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mscene\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mplot_scene\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m     \u001b[0;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'/scratch2/fml35/results/ROCA/results_per_scene/{}.json'\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mscene\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'r'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m         \u001b[0mannotations\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mjson\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '/scratch2/fml35/results/ROCA/results_per_scene/scene0621_00.json'"
     ]
    }
   ],
   "source": [
    "scene = \"scene0621_00\"\n",
    "plot_scene(scene,plot_scene=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "scene0011_00\n",
      "N 83 N filtered  83\n",
      "(90062, 3)\n",
      "(90062, 3)\n",
      "scene0011_01\n",
      "N 94 N filtered  94\n",
      "(19208, 3)\n",
      "(19208, 3)\n",
      "scene0015_00\n",
      "N 103 N filtered  103\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "# import random\n",
    "# random.seed(3)\n",
    "# Find scenen with not too many objects\n",
    "scenes = sorted(os.listdir('/scratch2/fml35/results/ROCA/results_per_scene_own_1_reformated'))\n",
    "# random.shuffle(scenes)\n",
    "# for i in range(len(scenes)):\n",
    "#     with open('/scratch2/fml35/results/ROCA/results_per_scene_own_1_reformated/' + scenes[i],'r') as f:\n",
    "#         annotations = json.load(f)\n",
    "#     scene = scenes[i].split('.')[0]\n",
    "#     if len(annotations) < 20:\n",
    "#         break\n",
    "scene = \"scene0621_00\"\n",
    "# print(scene)\n",
    "# print('NOT FILTERED')\n",
    "for scene_file in scenes:\n",
    "    scene = scene_file.split('.')[0]\n",
    "    print(scene)\n",
    "    plot_scene(scene,plot_scene=True)\n",
    "    #break\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1bd25495d76b499386348ac7b0541d5a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "with open('/scratch2/fml35/results/ROCA/gt_per_scene/{}.json'.format(scene),'r') as f:\n",
    "    annotations = json.load(f)\n",
    "\n",
    "plot = k3d.plot()\n",
    "for i in range(len(annotations)):\n",
    "    vert,face = load_mesh(shapenet_path,annotations[i][\"category\"],annotations[i][\"id_cad\"],annotations[i][\"r\"],annotations[i][\"t\"],annotations[i][\"s\"])\n",
    "    plot += k3d.mesh(vert,face,color=(64 + 128 * 256))\n",
    "plot.display()\n",
    "\n",
    "[-0.38479394 -2.75659412 -0.28431616]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/mifs/fml35/environments/shape_env/lib/python3.7/site-packages/traittypes/traittypes.py:101: UserWarning: Given trait value dtype \"float64\" does not match required type \"float32\". A coerced copy has been created.\n",
      "  np.dtype(self.dtype).name))\n",
      "/home/mifs/fml35/environments/shape_env/lib/python3.7/site-packages/traittypes/traittypes.py:101: UserWarning: Given trait value dtype \"int64\" does not match required type \"uint32\". A coerced copy has been created.\n",
      "  np.dtype(self.dtype).name))\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e577df85021f460ba4611e0e8605f24a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "N 52\n"
     ]
    }
   ],
   "source": [
    "# with open('/scratch2/fml35/results/ROCA/results_per_scene_filtered_reformated/scene0011_00.json','r') as f:\n",
    "#     annotations = json.load(f)\n",
    "\n",
    "# plot = k3d.plot()\n",
    "# for i in range(len(annotations)):\n",
    "#     vert,face = load_mesh(shapenet_path,annotations[i][\"category\"],annotations[i][\"id_cad\"],annotations[i][\"r\"],annotations[i][\"t\"],annotations[i][\"s\"])\n",
    "#     plot += k3d.mesh(vert,face,color=(64 + 128 * 256))\n",
    "# plot.display()\n",
    "# print('N',len(annotations))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "2b32248b32cb18190abbd4f0a784a70338ce7d4765f38bc190763b9ee5f2d639"
  },
  "kernelspec": {
   "display_name": "Python 3.7.10 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
